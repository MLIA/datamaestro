{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Datamaestro This projects aims at grouping utilities to deal with the numerous and heterogenous datasets present on the Web. It aims at being a reference for available resources, listing datasets a tool to automatically download and process resources (when freely available) integration with the experimaestro experiment manager. (planned) a tool that allows to copy data from one computer to another Each datasets is uniquely identified by a qualified name such as com.lecun.mnist , which is usually the inversed path to the domain name of the website associated with the dataset. The main repository only deals with very generic processing (downloading, basic pre-processing and data types). Plugins can then be registered that provide access to domain specific datasets. List of repositories NLP and information access related dataset image-related dataset machine learning contains standard ML datasets Detailed example Python definition of datasets Each dataset (or a set of related datasets) is described in Python using a mix of declarative and imperative statements. Its syntax is described in the documentation . For MNIST, this gives from datamaestro_image.data import ImageClassification , LabelledImages , Base from datamaestro.data.ml import Supervised from datamaestro.data.tensor import IDX from datamaestro.download.single import filedownloader from datamaestro.definitions import dataset @filedownloader ( \"train_images.idx\" , \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\" ) @filedownloader ( \"train_labels.idx\" , \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\" ) @filedownloader ( \"test_images.idx\" , \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\" ) @filedownloader ( \"test_labels.idx\" , \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\" ) @dataset ( ImageClassification , url = \"http://yann.lecun.com/exdb/mnist/\" , ) def MNIST ( train_images , train_labels , test_images , test_labels ): \"\"\"The MNIST database The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. \"\"\" return { \"train\" : LabelledImages ( images = IDX ( path = train_images ), labels = IDX ( path = train_labels ) ), \"test\" : LabelledImages ( images = IDX ( path = test_images ), labels = IDX ( path = test_labels ) ), } Retrieve and download The commmand line interface allows to download automatically the different resources. Datamaestro extensions can provide additional processing tools. $ datamaestro search mnist com.lecun.mnist $ datamaestro prepare com.lecun.mnist INFO:root:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz: 32 .8kB [ 00 :00, 92 .1kB/s ] INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz: 9 .92MB [ 00 :00, 10 .6MB/s ] INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte ...JSON... The previous command also returns a JSON on standard output { \"train\" : { \"images\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte\" }, \"labels\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte\" } }, \"test\" : { \"images\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte\" }, \"labels\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte\" } }, \"id\" : \"com.lecun.mnist\" } For those using Python, this is even better since the IDX format is supported In [ 1 ]: from datamaestro import prepare_dataset In [ 2 ]: ds = prepare_dataset ( \"com.lecun.mnist\" ) In [ 3 ]: ds . train . images . data () . dtype , ds . train . images . data () . shape Out [ 3 ]: ( dtype ( 'uint8' ), ( 60000 , 28 , 28 ))","title":"Home"},{"location":"#datamaestro","text":"This projects aims at grouping utilities to deal with the numerous and heterogenous datasets present on the Web. It aims at being a reference for available resources, listing datasets a tool to automatically download and process resources (when freely available) integration with the experimaestro experiment manager. (planned) a tool that allows to copy data from one computer to another Each datasets is uniquely identified by a qualified name such as com.lecun.mnist , which is usually the inversed path to the domain name of the website associated with the dataset. The main repository only deals with very generic processing (downloading, basic pre-processing and data types). Plugins can then be registered that provide access to domain specific datasets.","title":"Datamaestro"},{"location":"#list-of-repositories","text":"NLP and information access related dataset image-related dataset machine learning contains standard ML datasets","title":"List of repositories"},{"location":"#detailed-example","text":"","title":"Detailed example"},{"location":"#python-definition-of-datasets","text":"Each dataset (or a set of related datasets) is described in Python using a mix of declarative and imperative statements. Its syntax is described in the documentation . For MNIST, this gives from datamaestro_image.data import ImageClassification , LabelledImages , Base from datamaestro.data.ml import Supervised from datamaestro.data.tensor import IDX from datamaestro.download.single import filedownloader from datamaestro.definitions import dataset @filedownloader ( \"train_images.idx\" , \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\" ) @filedownloader ( \"train_labels.idx\" , \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\" ) @filedownloader ( \"test_images.idx\" , \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\" ) @filedownloader ( \"test_labels.idx\" , \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\" ) @dataset ( ImageClassification , url = \"http://yann.lecun.com/exdb/mnist/\" , ) def MNIST ( train_images , train_labels , test_images , test_labels ): \"\"\"The MNIST database The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. \"\"\" return { \"train\" : LabelledImages ( images = IDX ( path = train_images ), labels = IDX ( path = train_labels ) ), \"test\" : LabelledImages ( images = IDX ( path = test_images ), labels = IDX ( path = test_labels ) ), }","title":"Python definition of datasets"},{"location":"#retrieve-and-download","text":"The commmand line interface allows to download automatically the different resources. Datamaestro extensions can provide additional processing tools. $ datamaestro search mnist com.lecun.mnist $ datamaestro prepare com.lecun.mnist INFO:root:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz: 32 .8kB [ 00 :00, 92 .1kB/s ] INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz into /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte INFO:root:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz: 9 .92MB [ 00 :00, 10 .6MB/s ] INFO:root:Transforming file INFO:root:Created file /home/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte ...JSON... The previous command also returns a JSON on standard output { \"train\" : { \"images\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-images-idx3-ubyte\" }, \"labels\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/train-labels-idx1-ubyte\" } }, \"test\" : { \"images\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-images-idx3-ubyte\" }, \"labels\" : { \"path\" : \"/data/bpiwowar/datamaestro/data/image/com/lecun/mnist/t10k-labels-idx1-ubyte\" } }, \"id\" : \"com.lecun.mnist\" } For those using Python, this is even better since the IDX format is supported In [ 1 ]: from datamaestro import prepare_dataset In [ 2 ]: ds = prepare_dataset ( \"com.lecun.mnist\" ) In [ 3 ]: ds . train . images . data () . dtype , ds . train . images . data () . shape Out [ 3 ]: ( dtype ( 'uint8' ), ( 60000 , 28 , 28 ))","title":"Retrieve and download"},{"location":"developping/","text":"Developing Main library To develop the main library, clone this repository and, from the main directory, use git clone https://github.com/experimaestro/datamaestro.git pip install -e . to install the command line tool and develop at the same time.","title":"Developping"},{"location":"developping/#developing","text":"","title":"Developing"},{"location":"developping/#main-library","text":"To develop the main library, clone this repository and, from the main directory, use git clone https://github.com/experimaestro/datamaestro.git pip install -e . to install the command line tool and develop at the same time.","title":"Main library"},{"location":"api/","text":"The API is composed of: Specify what to download Describing data","title":"Overview"},{"location":"api/data/","text":"Generic Package datamaestro.data datamaestro.base Class datamaestro.data.Base Arguments id : The unique dataset ID datamaestro.generic Class datamaestro.data.Generic Supertypes : datamaestro.base Arguments id : The unique dataset ID datamaestro.file Class datamaestro.data.File Supertypes : datamaestro.base Arguments id : The unique dataset ID path : None CSV data Package datamaestro.data.csv datamaestro.csv.generic Class datamaestro.data.csv.Generic Supertypes : datamaestro.file Arguments id : The unique dataset ID path : None names_row : None ignore : None columns() Returns the list of field names (if any) or None datamaestro.csv.matrix Class datamaestro.data.csv.Matrix Supertypes : datamaestro.csv.generic Arguments id : The unique dataset ID path : None names_row : None ignore : None target : None size_row : None columns() Returns the list of field names (if any) or None data() -> Tuple[List[str], ForwardRef('numpy.array')] Returns the list of fields and the numeric data Machine Learning Package datamaestro.data.ml datamaestro.ml.supervised Class datamaestro.data.ml.Supervised Supertypes : datamaestro.base Arguments id : The unique dataset ID test : The test dataset validation : The validation dataset train : The training dataset datamaestro.ml.folderbased Class datamaestro.data.ml.FolderBased Supertypes : datamaestro.base Arguments id : The unique dataset ID classes : None path : None Tensor Package datamaestro.data.tensor datamaestro.file Class datamaestro.data.tensor.IDX Supertypes : datamaestro.base Arguments id : The unique dataset ID path : None","title":"Data"},{"location":"api/data/#generic","text":"Package datamaestro.data","title":"Generic"},{"location":"api/data/#datamaestrobase","text":"Class datamaestro.data.Base","title":"datamaestro.base"},{"location":"api/data/#arguments","text":"id : The unique dataset ID","title":"Arguments"},{"location":"api/data/#datamaestrogeneric","text":"Class datamaestro.data.Generic Supertypes : datamaestro.base","title":"datamaestro.generic"},{"location":"api/data/#arguments_1","text":"id : The unique dataset ID","title":"Arguments"},{"location":"api/data/#datamaestrofile","text":"Class datamaestro.data.File Supertypes : datamaestro.base","title":"datamaestro.file"},{"location":"api/data/#arguments_2","text":"id : The unique dataset ID path : None","title":"Arguments"},{"location":"api/data/#csv-data","text":"Package datamaestro.data.csv","title":"CSV data"},{"location":"api/data/#datamaestrocsvgeneric","text":"Class datamaestro.data.csv.Generic Supertypes : datamaestro.file","title":"datamaestro.csv.generic"},{"location":"api/data/#arguments_3","text":"id : The unique dataset ID path : None names_row : None ignore : None","title":"Arguments"},{"location":"api/data/#columns","text":"Returns the list of field names (if any) or None","title":"columns()"},{"location":"api/data/#datamaestrocsvmatrix","text":"Class datamaestro.data.csv.Matrix Supertypes : datamaestro.csv.generic","title":"datamaestro.csv.matrix"},{"location":"api/data/#arguments_4","text":"id : The unique dataset ID path : None names_row : None ignore : None target : None size_row : None","title":"Arguments"},{"location":"api/data/#columns_1","text":"Returns the list of field names (if any) or None","title":"columns()"},{"location":"api/data/#data-tupleliststr-forwardrefnumpyarray","text":"Returns the list of fields and the numeric data","title":"data() -&gt; Tuple[List[str], ForwardRef('numpy.array')]"},{"location":"api/data/#machine-learning","text":"Package datamaestro.data.ml","title":"Machine Learning"},{"location":"api/data/#datamaestromlsupervised","text":"Class datamaestro.data.ml.Supervised Supertypes : datamaestro.base","title":"datamaestro.ml.supervised"},{"location":"api/data/#arguments_5","text":"id : The unique dataset ID test : The test dataset validation : The validation dataset train : The training dataset","title":"Arguments"},{"location":"api/data/#datamaestromlfolderbased","text":"Class datamaestro.data.ml.FolderBased Supertypes : datamaestro.base","title":"datamaestro.ml.folderbased"},{"location":"api/data/#arguments_6","text":"id : The unique dataset ID classes : None path : None","title":"Arguments"},{"location":"api/data/#tensor","text":"Package datamaestro.data.tensor","title":"Tensor"},{"location":"api/data/#datamaestrofile_1","text":"Class datamaestro.data.tensor.IDX Supertypes : datamaestro.base","title":"datamaestro.file"},{"location":"api/data/#arguments_7","text":"id : The unique dataset ID path : None","title":"Arguments"},{"location":"api/download/","text":"Single files Package datamaestro.download.single Downloads a file given by a URL @filedownloader(filename: str, url: str, transforms=None) filename ( str ): The filename within the data folder; the variable name corresponds to the filename without the extension url ( str ): The URL to download transforms ( ? ): Transform the file before storing it Concat the files in an archive @concatdownload(filename: str, url: str, transforms=None) filename ( str ): The filename within the data folder; the variable name corresponds to the filename without the extension url ( str ): The URL to download transforms ( ? ): Transform the file before storing it Archives Package datamaestro.download.archive Downloads and extract the content of the archive @zipdownloader(varname, url: str, subpath: str = None, files: Set[str] = None) varname ( ? ): The name of the variable when defining the dataset url ( str ): The archive URL subpath ( str ): A subpath in the archive; only files from this subpath will be extracted files ( Set[str] ): A set of files; if present, only download those Downloads and extract the content of the archive @tardownloader(varname, url: str, subpath: str = None, files: Set[str] = None) varname ( ? ): The name of the variable when defining the dataset url ( str ): The archive URL subpath ( str ): A subpath in the archive; only files from this subpath will be extracted files ( Set[str] ): A set of files; if present, only download those Links Package datamaestro.download.links Link with another dataset path @links(varname: str, **links: List[datamaestro.definitions.DatasetDefinition]) varname ( str ): The name of the variable when defining the dataset links ( List[datamaestro.definitions.DatasetDefinition] ): A list of Link to a folder @linkfolder(varname: str, proposals) varname ( str ): Name of the variable proposals ( ? ): List of potential paths Syncing Package datamaestro.download.sync Synchronize with Google sync @gsync(varname: str, url: str) varname ( str ): Variable name url ( str ): The google sync URL ( gs://... )","title":"Download"},{"location":"api/download/#single-files","text":"Package datamaestro.download.single","title":"Single files"},{"location":"api/download/#downloads-a-file-given-by-a-url","text":"@filedownloader(filename: str, url: str, transforms=None) filename ( str ): The filename within the data folder; the variable name corresponds to the filename without the extension url ( str ): The URL to download transforms ( ? ): Transform the file before storing it","title":"Downloads a file given by a URL"},{"location":"api/download/#concat-the-files-in-an-archive","text":"@concatdownload(filename: str, url: str, transforms=None) filename ( str ): The filename within the data folder; the variable name corresponds to the filename without the extension url ( str ): The URL to download transforms ( ? ): Transform the file before storing it","title":"Concat the files in an archive"},{"location":"api/download/#archives","text":"Package datamaestro.download.archive","title":"Archives"},{"location":"api/download/#downloads-and-extract-the-content-of-the-archive","text":"@zipdownloader(varname, url: str, subpath: str = None, files: Set[str] = None) varname ( ? ): The name of the variable when defining the dataset url ( str ): The archive URL subpath ( str ): A subpath in the archive; only files from this subpath will be extracted files ( Set[str] ): A set of files; if present, only download those","title":"Downloads and extract the content of the archive"},{"location":"api/download/#downloads-and-extract-the-content-of-the-archive_1","text":"@tardownloader(varname, url: str, subpath: str = None, files: Set[str] = None) varname ( ? ): The name of the variable when defining the dataset url ( str ): The archive URL subpath ( str ): A subpath in the archive; only files from this subpath will be extracted files ( Set[str] ): A set of files; if present, only download those","title":"Downloads and extract the content of the archive"},{"location":"api/download/#links","text":"Package datamaestro.download.links","title":"Links"},{"location":"api/download/#link-with-another-dataset-path","text":"@links(varname: str, **links: List[datamaestro.definitions.DatasetDefinition]) varname ( str ): The name of the variable when defining the dataset links ( List[datamaestro.definitions.DatasetDefinition] ): A list of","title":"Link with another dataset path"},{"location":"api/download/#link-to-a-folder","text":"@linkfolder(varname: str, proposals) varname ( str ): Name of the variable proposals ( ? ): List of potential paths","title":"Link to a folder"},{"location":"api/download/#syncing","text":"Package datamaestro.download.sync","title":"Syncing"},{"location":"api/download/#synchronize-with-google-sync","text":"@gsync(varname: str, url: str) varname ( str ): Variable name url ( str ): The google sync URL ( gs://... )","title":"Synchronize with Google sync"}]}